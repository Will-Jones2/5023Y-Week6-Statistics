---
title: 'Unit E-wk6 Statistics: Interactions'
author: "Will Jones"
output:
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Packages you will need for today:

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(modelr)
library(car)
library(qqplotr)
library(praise)
library(patchwork)
library(stargazer)
library(emmeans)

```


# 1. Grassland biomass data

This dataset comes from work published in 2009 by Hautier et al. (*Science*, **324**:636). 

The response variable is the above-ground biomass (g/m^2) of experimental plant communities exposed to fertilizer treatments and applying artificial light to the plant understorey. 

The experiment examined the effect of using fertiliser to increase plant biomass. Here we can compare fertilised and unfertilised treatments. 

A second hypothesis is that extra plant growth after fertilisation might be impeded by crowding and competition for light, so a third treatment includes the combination of fertilizer treatment and artificial light shone on the understorey of the plants, to see if this counteracts the effect of shading. 

Finally the design is made "fully factorial" with a treatment of light sources included on plants with no extra fertilizer applied.

Experiments with designs that feature combinations of different treatments are called factorial designs

Experiments that have all possible combinations are "full factorial" analyses. 

```{r, message=FALSE}
biomass <- read_csv("data/biomass.csv")

```

We should **always** think about sensible hypotheses plot and inspect our data first - and not simply rely on models without checking. 

<details><summary>**Question - Can you write a brief/sensible hypothesis for the effects of fertilizer and light on biomass?**</summary>

It is best to break down your hypotheses into sections and give direction

- The application of fertilizer **increases** the biomass of the experimental plant communities

- The application of light to the plant understorey **increases** the biomass of experimental plant communities

</details>


We should also plot our data to sense-check our ideas/hypotheses

```{r}
biomass %>% 
  ggplot(aes(x=FL, y=Biomass.m2))+
  geom_boxplot()+
  geom_jitter(width=0.1)+
  labs(x="Light & Fertilisation treatments", y="Above ground biomass")+
  ggtitle("A comparison of the effects of Light and Fertilisation \n on Above ground plant biomass")

praise::praise("${exclamation}! What a ${adjective} graph!")

```

Now that we have both a sensible hypothesis and an observation of an apparent difference between treatments, we are justified in producing a model with one variable (Treatment) and four levels (F-L-, F-L+, F+L-, F+L+) to test this effect. 

```{r}
model1 <- lm(Biomass.m2~FL, data=biomass)
summary(model1)

```
Here the intercept is F-L- (no fertiliser or light). The overall model summary appears to support our hypotheses. There are significant *mean differences* between our treatments and the intercept. 

If we want to plot the actual estimated means from our model, then these will be contained in `broom::augment()` but are probably easiest to pull out using the `emmeans()` function from the package of the [same name](https://aosmith.rbind.io/2019/03/25/getting-started-with-emmeans/#confidence-intervals-for-comparisons).


```{r}
emmeans::emmeans(model1, specs="FL") %>% 
  as_tibble() %>% 
  ggplot(aes(x=FL,
             y=emmean))+
  geom_pointrange((aes(ymin=lower.CL,
                       ymax=upper.CL)))

praise::praise("${exclamation}! This is just ${adjective}!")
  
```
### 1.1 Estimated means

**Remember** this is plotting the estimated means & adding the 95% confidence intervals for each mean. So this cannot be used directly for estimating **significant** differences or **effect sizes**.

### 1.2 Estimated mean differences

Let's go back to our estimated mean differences & note the size of each of the estimates

<details><summary>**Question - What do the three estimated differences of the mean tell us about the effect of fertiliser and light on biomass?**</summary>

If the combined effect of fertiliser and light was *additive* we would expect the F+L+ treatment to be roughly the sum of the other two mean differences (30+94) = 124. 

BUT the value is much greater than this FLF+L+ = 219. 


This indicates an *interaction* - where the combined effect of Fertiliser and Light is **greater** than we would expect from combining the treatments. 

</details>

# 2. Modelling an interaction

Our previous model does not properly isolate the effect of this interaction. This is because it treats these four treatment combinations as four entirely independent treatments. 

We know this is not really true, that instead these are four possible combinations of just **two** treatments. 

We need a model that that uses the *combination* of the two treatments to reflect the design and will explicitly estimate the interaction. 

```{r}
model2 <- lm(Biomass.m2~Light+Fert+Light:Fert, data=biomass)
summary(model2)
### Light:Fert specifies an interaction term
### There is a shorthand for this lm(Biomass.m2~Light*Fert) where * is a shorthand for main effects AND interactions

```
When we specify a model like this, the last line of the model (LightL+:FertF+) estimates the effect size of the interaction. 

Compare this to model1:

(219-124) = 95

So our estimated mean fro F+L+ is 219, if the effect of light is 30 and fertiliser is 93 then the interaction effect is what's left over - and now our model successfully estimates this. 

So to summarize:

The intercept is the mean for the unmanipulated control F-L-
```{r}
coef(model2)[1]
```
The estimated biomass for the Fertilised treatment (F+L-) is the intercept plus the coefficient value for fertilisation

```{r}
coef(model2)[1]+coef(model2)[2]
```

The estimated biomass for the Light treatment (F-L+) is 

```{r}
coef(model2)[1]+coef(model2)[3]
```

And to get the estimated mean of our final full combination treatment, we take the baseline intercept and both additive main effects *and* the interaction term

```{r}
coef(model2)[1]+coef(model2)[2]+coef(model2)[3]+coef(model2)[4]
```

Another way to think about the interaction term, is that if there was no absolutely **no interaction** between fertilizer treatments and light treatments then the effect size of the interaction term would be **zero**. 

So the estimate would be zero and our additive effects would be the whole story. 

## 2.1 Main effects in the presence of a significant interaction

If we look at the summary for this model again we can see that Light appears to be non-significant *P* = 0.36

However we know that this does not tell us the whole story - here this is the average effect of Light on growth across both fertilised and non-fertilised treatments. 

We know because of our significant interaction term that whether the light has an effect depends on the fertilisation treatment - the effect of adding light is stronger on fertilised plants. 

In other words, regardless of the test results for Light and Fert, ‘both’ treatment factors are important **because** there is a significant interaction effect

So when describing a model always work from the bottom up (interactions first). If you detect a significant interaction term, then you must **must** include all the main effects that make up that treatment as well. 

Sometimes the interaction effect may be very weak, and the main effects much stronger overall in which case you definitely need to report all main and interaction effects when writing up your results. 

# 3. ANOVA tables

If we wish to report our results we can use ANOVA tables. Remember a complex model or one with more than two levels for factors will produce estimates for *each* two-way comparison with the intercept. If we want an *overall* summary of an effect we can use ANOVA tables.

These present simple summaries of the whole analysis - but they can get a little tricky to interpret once we have significant interactions. 

```{r}
summary(aov(model2))
```

## 3.1 F-values for main effects

The main disadvantage of ANOVA tables run by the `summary(aov())` route is that they work by sequentially *adding* effects. 

This tests the main effect of factor A, followed by the main effect of factor B after the main effect of A, followed by the interaction effect AB after the main effects. 

The result is that the order in which variables were specified in the model are important AND it is bad because it *over-estimates* the significance of main effects *when* there are interactions.

This is known as Type I Sums of Squares. 

This is ok then for looking at the top-level interaction terms **only** - and we can reproduce the ANOVA for the interaction term easily by running an *F*-test comparing our complex model (2) with a simpler model (3). 

This is a **good** way to confirm that an interaction effect is significant. If it is not, you can remove it from your model (use the simple one instead). 

```{r}
model3 <- lm(Biomass.m2 ~ Light + Fert, data = biomass) ## simple model - interaction removed
anova(model2,model3, test="F")

```

## 3.2 Type I,II,III sum of squares

But what about producing F values for the main effects, when there are significant interactions in the model?
Enter `car::Anova` which can specify type II and type III Sums of Squares. 

```{r}
car::Anova(model2, type="III")
```
What you should see now is that the F-value and significance of our interaction term never changed - but the P-values from the main effects are now identical to our `summary()` table. So this is a robust output for summarising the F-values of each main term and interaction in our model. 

E.g. Fertiliser had a sigificant effect on biomass *F*~1,60~ = 8.2, *P* = 0.006. 

## 3.3 How to choose Type I,II, or III Sums of squares

Type I - compare the effect of removing an interaction or main effect from a model - useful for justifying model simplification

Type II - Most accurate for describing a model with **main effects only**

Type III - Most accurate for describing main effects and interactions **when there is an interaction term in the model**. 


### Read more about sums of squares

[Here](https://mcfromnz.wordpress.com/2011/03/02/anova-type-iiiiii-ss-explained/), 
[and here](https://towardsdatascience.com/anovas-three-types-of-estimating-sums-of-squares-don-t-make-the-wrong-choice-91107c77a27a#:~:text=Type%20I%20Sums%20of%20Squares%2C%20or%20also%20called%20Sequential%20Sums,of%20variation%20to%20variable%20A)


### Summary

The test rejects the null hypothesis of no interaction effect of light addition and fertilization, (though only just!). And we could report this as:

There was a significant interactive effect of light addition and fertilisation (*F*~1,60 = 4.25, *P* = 0.044). And we could also report our main effects using Type III Sums of Squares. 

IF our interaction was non-significant we would have failed to reject our Null Hypothesis, and we could remove the interaction term and re-do the model with main effects only - and test that as a separate hypothesis. 

But as we know an alternative to ANOVA reporting is to estimate *effect sizes* with 95% Confidence Intervals. 


# 4. Confidence intervals and estimates

Providing estimates with CI allows a test of interaction effects, but also provides information on the strength of the effect (how strong is the interaction in terms of the effect on bio-mass production).

- Important reminder our linear models allow us to produce two *different but related* estimates and confidence intervals (**means** and **mean differences**), understanding and interpreting these correctly is important for results interpretation. 

Let's dive in using `broom::tidy()` because it allows us to easily add confidence intervals to model estimates

```{r}
broom::tidy(model2, conf.int=T)
```

Remember the only estimated mean in this model is the Intercept (here F-L-) which could be reported as 355.79 (95%CI: 309.51-402.1) all the other rows represent estimated mean **differences**. These are pretty straightforward to interpret, if the 95% confidence interval spans zero, then we cannot report a mean difference that is different to zero at *P* < 0.05. 


So let's plot these mean differences and confidence intervals

```{r}
tidy_model <- broom::tidy(model2, conf.int=T) 

tidy_model

tidy_model %>% 
  ggplot(aes(x=estimate, 
             y=term))+
  geom_pointrange(aes(xmin=conf.low, 
                      xmax=conf.high))+
  geom_vline(xintercept=0,         ### set intercept to zero, if an interval crosses zero it means "zero difference"
             linetype="dashed")

```

From this we can easily see that we do not have greater than 95% confidence that the estimated mean difference between the two light treatments is greater than zero. (Though we should also remember that part of the reason for this, is that we know it has a greater effect on fertilised plants than unfertilised plants). 

From our confidence intervals we can also report that the addition of fertiliser increases plant biomass by *a minimum* of 28.23 g/m^2 and the combined effect of light and fertilisation increases biomass by *at least* 2.84 g/m^2 **more** than would expect from the *additive* effects of light and fertilisation. (Note I am using the lowest confidence interval margins here). 

### More Reading

[Estimated means vs estimated difference between means](https://onlinestatbook.com/2/estimation/difference_means.html)

## 4.1 Emmeans

It is much more common for a researcher to be interested in the difference between means than in the specific values of the means themselves. And this is the direct output from our linear model - the *estimated mean differences* but we can also use our model to produce the estimated means and confidence intervals directly for our different categories. 

This is useful for plotting how well your model describes/explains the dataset. 

The easiest way to do this is with the `emmeans` package, that you used earlier

```{r}
means <- emmeans::emmeans(model2, specs= ~Fert:Light, type="response") %>% confint() 
 ### estimated means as predicted by the linear model, pipe to confint to add 95% Confidence intervals to estimates


# means <- emmeans::emmeans(model2, specs= pairwise~Fert:Light, type="response") %>% confint()
## add the argument pairwise ~ in front of the variables to produce a second table of $contrasts. 
# Contrasts allows you to estimate average and minimum effect size differences between all factor levels - this is an example of a post-hoc test - a term you should be familiar with from first year. 

plot1 <- means%>% ## emmeans does not output in a table format - pipe to as_tibble() to convert it. 
  as_tibble() %>% 
  ggplot(aes(x=Fert,
             y=emmean,
             group=Light))+
  geom_line(aes(linetype=Light))

plot1

```

## TASK 1

<details><summary> Use `geom_pointrange()` to add 95% Confidence intervals to these mean estimates </summary>

```{r}
plot1+geom_pointrange(aes(ymin=lower.CL, 
                      ymax=upper.CL,
                      ))

```
</details>

# 5. Write up

## TASK 2

This might seem a little more challenging than previous write-ups but we should have a go at presenting these results.

Here we should build on previous attempts in that I will write this up as a full results paragraph in the style I want you to provide for your summative. 

- We can report the full model in a table, if we use the stargazer package it will include 95% CI for the mean differences. (Remember this is great for an instant and report worthy table when producing a markdown document - but will look like nonsense if run in R as it outputs HTML).

- We can refer to useful figures

- We should report the full model ANOVA (from broom::glance or the bottom line of the summary() table)

- Describe the differences observed, include values and CI where appropriate. 


<details><summary> **My write-up** </summary>

**Combined effects of Fertiliser and Light Treatments on Biomass**


I hypothesised there would be positive interaction effect on the biomass of experimental plant communities given a combined fertiliser and artifical light application. Plants given a fertiliser treatment may experience increased competition for light as they grow, and so the application of an artificial light source to the plant understorey is expected to have a greater impact here than on the less nutrient-rich treatment. 

To test this hypothesis I compared plant biomass levels in g/m^2 using a general linear model with factorial predictors of light and fertiliser treatment and an interaction term of these two predictors. 

I found a strong overall effect of light and fertiliser treatment on the biomass of plants in these experimental communities (*F*~3,60~ = 17.6, *P* <0.001, Full model estimates **Table 1**). The addition of Fertiliser had a strong positive effect on biomass with an average increase in yield of 93g/m^2 (95%CI: 28.23-159.15). The application of light to the understorey of the plants did not have a significant effect on plant growth as a main effect ( estimated increase of 30.12g/m^2 (95%CI: -35.33-95.58), but there was a significant positive interaction effect of combined light and fertiliser application that increased plant biomass by an extra 95.4 g/m^2 (95% CI: 2.84-187.98) above that predicted by the additive main effects alone (**Figure 1**).

This suggests that biomass production may be limited by different factors in the under-storey and upper canopy of the plants. For example with the addition of fertiliser competition for light may be more intense, or more light limited.

```{r, fig.cap="Figure 1. Estimated mean biomass of experimental plant communities under Fertiliser and Light treatments. Fertiliser and light treatments combine to produce a significant positive interaction. Central points are estimated treatment means with 95% Confidence intervals, plotted alongside raw values from the dataset"}
plot1+geom_pointrange(aes(ymin=lower.CL, 
                      ymax=upper.CL,
                      colour=Light))+
  geom_jitter(data=biomass, aes(x=Fert, 
                                y=Biomass.m2,
                                group=Light,
                                colour=Light),
              width=0.1, 
              alpha=0.6)+
   geom_line(aes(linetype=Light, colour=Light))+
  labs(x="Fertiliser",
       y=expression(paste("Estimated mean biomass ", g/m^2)))+
  scale_colour_manual(values=c("darkorange", "purple"))+
  theme_classic()+
     theme(plot.caption=element_text(hjust=0))

```

```{r, results="asis"}
stargazer::stargazer(model2, 
                     type="html", 
                     ci.custom = list(confint(model2)), ###turns out if you put CI=T, then stargazer assumes a normal dist (1.96*S.E) so to get the most accurate CI supply them using the custom argument and confint. 
                     title= "Table 1. Summary model output for the interaction of Fertiliser and Light on Experimental Plant Community Biomass")

##optional
###notes.append = FALSE, notes =c("<sup>&sstarf;</sup>p<0.1; <sup>&sstarf;&sstarf;</sup>p<0.05; <sup>&sstarf;&sstarf;&sstarf;</sup>p<0.01))

### this extra code from notes.append onwards fixes a minor issue of not including the number of stars at the end of the table in HTML output only

```

</details>

# 6. Summary

We have now progressed away from simple 'one-way' designs into more complex multiple predictor statistics that include interactions as well as main effects. 

Interactions are assessed relative to a null hypothesis of an additive effect only. 

Interactions can be **positive** (when there effects are greater than the additive expectation) or **negative** (if they are less than the additive expectation). 

When we treated this as four separate treatments, there was no way to establish the effect of light, or to separate out the effect size of interactions between treatments.

However, a proper factorial analysis which includes an interaction term allows us to show that the combination of light and fertilise is greater than their additive expectation. 

This suggests that biomass production may be limited by different factors in the under-storey and upper canopy of the plants. For example with the addition of fertiliser competition for light may be more intense, or more light limited. Adding light to these plants increases biomass substantially. 

## 6.1 Test yourself

You should complete these and check the solutions below! 

A researcher is investigating the impacts of stream water temperature (∘C), volumetric flow rate (cubic feet per second, cfs), and substrate composition (gravel, sand, or mud) on chlorophyll concentration (μg/L). After thoroughly exploring and thinking really hard about the data, they determine that multiple linear regression *without* an interaction is an appropriate approach to explore relationships between variables.

Performing multiple linear regression in R, they find the following model:

$$chlorophyll = 19.2 + 1.3*(temperature) - 0.04*(flow_rate) - 8.6*(gravel) - 5.1*(sand)$$

<details><summary> **A. What are the predictor and outcome variables, and what type of variable is each?** </summary>

- Dependent variable: chlorophyll concentration (a continuous variable)

- Predictor variable: water temperature (a continuous variable)

- Predictor variable: flow rate (a continuous variable)

- Predictor variable: stream substrate (a categorical variable with three levels: mud, gravel, or sand

</details>

<details><summary> **B. What is the reference level for stream substrate composition?** </summary>

The reference level for stream substrate is mud (the level that does not appear explicitly in the regression model)

</details>

<details><summary> **C. Interpret each of the model coefficients** 

- Write a sentence describing what the 1.3 coefficient for temperature means

- Write a sentence describing what the -0.04 coefficient for flow_rate means

- Write a sentence describing what the -8.6 coefficient for gravel means

- Write a sentence describing what the -5.1 coefficient for sand means

</summary>

- Write a sentence describing what the 1.3 coefficient for temperature means:

**For each 1 ∘C increase in water temperature, we expect chlorophyll concentration to increase by 1.3 μg/L, on average.**

- Write a sentence describing what the -0.04 coefficient for flow_rate means:

**For each 1 cfs increase in flow rate, we expect chlorophyll concentration to decrease by 0.04 μg/L, on average.**

- Write a sentence describing what the -8.6 coefficient for gravel means: 

**If stream conditions are otherwise the same, we expect chlorophyll concentration in a stream with gravel substrate to be 8.6 μg/L less than in a stream with mud substrate, on average.**

- Write a sentence describing what the -5.1 coefficient for sand means: 

**If stream conditions are otherwise the same, we expect chlorophyll concentration in a stream with sand substrate to be 5.1 μg/L less than in a stream with mud substrate, on average.**

</details>

<details><summary> **D. Make chlorophyll concentration predictions for streams with the following conditions:** 

What is the predicted chlorophyll concentration for a stream with a flow rate of 184 cfs, temperature of 18.4 ∘C, with gravel substrate?

What is the predicted chlorophyll concentration for a stream with a flow rate of 386 cfs, temperature of 16.1 ∘C, with mud substrate?

</summary>

What is the predicted chlorophyll concentration for a stream with a flow rate of 184 cfs, temperature of 18.4 ∘C, with gravel substrate?

**chlorophyll = 19.2 + 1.3*(18.4) - 0.04*(184) - 8.6*(1) - 5.1*(0) = 27.2 μg/L**

What is the predicted chlorophyll concentration for a stream with a flow rate of 386 cfs, temperature of 16.1 ∘C, with mud substrate?

**chlorophyll = 19.2 + 1.3*(16.1) - 0.04*(386) - 8.6*(0) - 5.1*(0) = 24.7 μg/L**

</details>


## 6.2 Checklist

- Make sure you think about your data *before* you start making models

- Make sure you visualise your data *before* you start making models

- Make sure you have a clear hypothesis *before* you start making models

- You can *over-fit* your model and this is generally better than *under-fitting*

- But if a term can be removed without significantly affecting the fit of the model, then you can do this - and write this up. Then move on to testing main effects. 

